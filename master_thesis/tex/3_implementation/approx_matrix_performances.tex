The performances of the inverse subspace iteration for 50 and 500 eigenvalues:

\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.5\textwidth}
   \input{tex/plots/inv_it_runtime_50}
   \caption{50 eigenvalues.}
  \end{subfigure}
  \begin{subfigure}[b]{0.45\textwidth}
   \input{tex/plots/inv_it_runtime_500}
   \caption{500 eigenvalues.}
  \end{subfigure}
  \caption{Runtime of the inverse subspace iteration part of the algorithm.}
\end{figure}

When increasing a low number of processors, we see a sharp improvement of the performances in both cases.
But the runtime stagnates quickly when the number of processors grows and we even observe a raise of the runtime.
The algorithm reaches its parallelisation limit and the communication overhead takes over.

We know from the runtime performances that the inverse iteration part of the algorithm is not scaling correctly.
For any amount of computed eigenvalues, when we increase the number of processes, the proportion of time spent computing the eigenvalues increases.
For 500 eigenvalues and 128 processors, we spend more than 99\% of the time computing the eigenvalues.
This confirms that the algorithm does not quite scale yet.

We now have a look at the internal steps of the inverse power method to see where lies the problem.
The algorithm consists of iteratively solving \(m\) linear systems, orthonormalising the vectors and computing the residual norm.
Here is the proportion of each step of the inverse subspace interation for the computation of 50 and 500 eigenvalues:

\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.4\textwidth}
   \input{tex/plots/inv_it_proportion_50}
   \caption{50 eigenvalues.}
  \end{subfigure}
  \begin{subfigure}[b]{0.4\textwidth}
   \input{tex/plots/inv_it_proportion_500}
   \caption{500 eigenvalues.}
  \end{subfigure}
  \caption{Proportion of each step in the inverse subspace iteration.}
\end{figure}

We observe that the Gram-Schmidt orthogonalisation is the limiting factor and is the most time-consuming step of the inverse iteration as the number of processors grows.
It is a well-known problem that the simple Gram-Schmidt process is actually difficult to parallelise efficiently.
Small optimisations for a parallel Gram-Schmidt orthogonalisation exist \cite{katagiri_parallel_gram_schmidt_2003} but they do not properly solve the problem.

This issue will be difficult to overcome completely.
But fundamentally, the orthogonalisation is used to stabilise the algorithm.
To accelerate our algorithm further, we try to orthogonalise the vectors \(X_k\) every second iteration instead of every iteration.
We present below the resulting performances:

\begin{figure}[H]
  \centering
  \begin{subfigure}[b]{0.5\textwidth}
   \input{tex/plots/inv_it_runtime_50_gs}
   \caption{50 eigenvalues.}
  \end{subfigure}
  \begin{subfigure}[b]{0.45\textwidth}
   \input{tex/plots/inv_it_runtime_500_gs}
   \caption{500 eigenvalues.}
  \end{subfigure}
  \caption{Runtime of the inverse subspace iteration part of the algorithm.}
\end{figure}

We observe ...

